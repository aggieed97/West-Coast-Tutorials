{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_breast_cancer, fetch_lfw_people\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "from keras.layers import Dense, Conv2D, MaxPool2D, Flatten\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = data.data\n",
    "y = 1 - data.target # to make malignant 1 and benign 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y) # don't need to scale yet because doing it in Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "ss = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model_funk(layer_one_neurons = 30, layer_two_neurons = 15):  # can make neurons dynamic\n",
    "    model = Sequential()\n",
    "    \n",
    "    model.add(Dense(layer_one_neurons, input_dim=30, activation = 'relu')) # 30 neurons\n",
    "    model.add(Dense(layer_two_neurons, activation = 'relu'))\n",
    "    model.add(Dense(1, activation = 'sigmoid'))  # 1 hidden layer\n",
    "    \n",
    "    model.compile(loss = 'binary_crossentropy', optimizer = 'adam', metrics = ['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "the_model = KerasClassifier(build_fn=model_funk, epochs = 10, verbose = 0)   #function that creates a model and returns it"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('ss', ss),\n",
    "    ('model', the_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9647887307153621\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'model__epochs': 10,\n",
       " 'model__layer_one_neurons': 35,\n",
       " 'model__layer_two_neurons': 15}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params = {\n",
    "    'model__epochs' : [10],\n",
    "    'model__layer_one_neurons' : [15, 35],\n",
    "    'model__layer_two_neurons' : [15, 20]\n",
    "}\n",
    "gs = GridSearchCV(pipe, param_grid = params)\n",
    "gs.fit(X_train, y_train)\n",
    "print(gs.best_score_)\n",
    "gs.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9860139864308017"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gs.score(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "The Python Imaging Library (PIL) is required to load data from jpeg files",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36m_load_imgs\u001b[1;34m(file_paths, slice_, color, resize)\u001b[0m\n\u001b[0;32m    143\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 144\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    145\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'imread'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     18\u001b[0m \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 19\u001b[1;33m     \u001b[1;32mfrom\u001b[0m \u001b[0mPIL\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     20\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'PIL'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36m_load_imgs\u001b[1;34m(file_paths, slice_, color, resize)\u001b[0m\n\u001b[0;32m    145\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 146\u001b[1;33m             \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpilutil\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimread\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    147\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\scipy\\misc\\pilutil.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     20\u001b[0m \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 21\u001b[1;33m     \u001b[1;32mimport\u001b[0m \u001b[0mImage\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     22\u001b[0m     \u001b[1;32mimport\u001b[0m \u001b[0mImageFilter\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'Image'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-3-1bb7d3ab67a1>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# images\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfetch_lfw_people\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmin_faces_per_person\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m35\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# give me only people with 70 faces in the data set\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36mfetch_lfw_people\u001b[1;34m(data_home, funneled, resize, min_faces_per_person, color, slice_, download_if_missing)\u001b[0m\n\u001b[0;32m    333\u001b[0m     faces, target, target_names = load_func(\n\u001b[0;32m    334\u001b[0m         \u001b[0mdata_folder_path\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mresize\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 335\u001b[1;33m         min_faces_per_person=min_faces_per_person, color=color, slice_=slice_)\n\u001b[0m\u001b[0;32m    336\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    337\u001b[0m     \u001b[1;31m# pack the results as a Bunch instance\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    560\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    561\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 562\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_cached_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    563\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    564\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__reduce__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36m_cached_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m    508\u001b[0m                           \u001b[1;34m'directory %s'\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    509\u001b[0m                         % (name, argument_hash, output_dir))\n\u001b[1;32m--> 510\u001b[1;33m             \u001b[0mout\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcall\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    511\u001b[0m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmmap_mode\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    512\u001b[0m                 \u001b[1;31m# Memmap the output at the first call to be consistent with\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\externals\\joblib\\memory.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    742\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_verbose\u001b[0m \u001b[1;33m>\u001b[0m \u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    743\u001b[0m             \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mformat_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 744\u001b[1;33m         \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    745\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_persist_output\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0moutput\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0moutput_dir\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    746\u001b[0m         \u001b[0mduration\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36m_fetch_lfw_people\u001b[1;34m(data_folder_path, slice_, color, resize, min_faces_per_person)\u001b[0m\n\u001b[0;32m    234\u001b[0m     \u001b[0mtarget\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msearchsorted\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtarget_names\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mperson_names\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    235\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 236\u001b[1;33m     \u001b[0mfaces\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_load_imgs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfile_paths\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mslice_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolor\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mresize\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    237\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    238\u001b[0m     \u001b[1;31m# shuffle the faces with a deterministic RNG scheme to avoid having\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\datasets\\lfw.py\u001b[0m in \u001b[0;36m_load_imgs\u001b[1;34m(file_paths, slice_, color, resize)\u001b[0m\n\u001b[0;32m    147\u001b[0m         \u001b[1;32mfrom\u001b[0m \u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmisc\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mimresize\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    148\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mImportError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 149\u001b[1;33m         raise ImportError(\"The Python Imaging Library (PIL)\"\n\u001b[0m\u001b[0;32m    150\u001b[0m                           \" is required to load data from jpeg files\")\n\u001b[0;32m    151\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: The Python Imaging Library (PIL) is required to load data from jpeg files"
     ]
    }
   ],
   "source": [
    "# images\n",
    "\n",
    "data = fetch_lfw_people(min_faces_per_person=35)  # give me only people with 70 faces in the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x248236ef748>"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x248227ef588>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "grays = np.arange(256).reshape(16, 16)  # list of numbers from 0 to 255 to represent 256 color scale; 16, 16 to get it into a square to look at matplotlib 16x16=256\n",
    "plt.imshow(grays, cmap =plt.cm.gray)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "images",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     60\u001b[0m         \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyError\u001b[0m: 'images'",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-6c7b6d544e84>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mdata\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimages\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\envs\\tensorflow\\lib\\site-packages\\sklearn\\utils\\__init__.py\u001b[0m in \u001b[0;36m__getattr__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m     61\u001b[0m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     62\u001b[0m         \u001b[1;32mexcept\u001b[0m \u001b[0mKeyError\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 63\u001b[1;33m             \u001b[1;32mraise\u001b[0m \u001b[0mAttributeError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mkey\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     64\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__setstate__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: images"
     ]
    }
   ],
   "source": [
    "data.images[0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:tensorflow]",
   "language": "python",
   "name": "conda-env-tensorflow-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
